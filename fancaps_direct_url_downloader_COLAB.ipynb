{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJiOT_ZB2vIv"
      },
      "outputs": [],
      "source": [
        "# Fancaps Direct URL Downloader\n",
        "# By citronlegacy:\n",
        "# https://github.com/citronlegacy/fancaps-direct-url-downloader\n",
        "#\n",
        "# This script downloads a list of direct image URLs from Fancaps.\n",
        "# Inspired by KitsunekoFi's fancaps-dl (https://github.com/KitsunekoFi/fancaps-dl),\n",
        "# which is a more elaborate downloader supporting episodes and movie URLs.\n",
        "#\n",
        "# Usage:\n",
        "#   - Paste your image URLs in the 'urls_text' multiline string.\n",
        "#   - Set your preferred output folder.\n",
        "#   - Run the script.\n",
        "\n",
        "import os\n",
        "import time\n",
        "import concurrent.futures\n",
        "import urllib.request\n",
        "\n",
        "# -------------------------\n",
        "# User Configuration\n",
        "# -------------------------\n",
        "\n",
        "USER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"\n",
        "\n",
        "# Paste your URLs here (one URL per line)\n",
        "urls_text = \"\"\"\n",
        "https://cdni.fancaps.net/file/fancaps-movieimages/4839637.jpg\n",
        "https://cdni.fancaps.net/file/fancaps-movieimages/4839642.jpg\n",
        "https://cdni.fancaps.net/file/fancaps-movieimages/4839650.jpg\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Output folder for downloaded images\n",
        "OUTPUT_FOLDER = \"./downloads\"\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "# Pause configuration\n",
        "PAUSE_EVERY_N = 3  # Number of downloads after which to pause for 1 second - You can probably download more than 3 at once but 3 is safe. Don't overload Fancaps.\n",
        "\n",
        "# -------------------------\n",
        "# Parse URLs\n",
        "# -------------------------\n",
        "\n",
        "image_urls = [line.strip() for line in urls_text.strip().split('\\n') if line.strip()]\n",
        "\n",
        "# -------------------------\n",
        "# HTTP headers\n",
        "# -------------------------\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': USER_AGENT\n",
        "}\n",
        "\n",
        "# If needed, add cf_clearance cookie to headers like this:\n",
        "# cf_clearance = \"your_cf_clearance_cookie_here\"\n",
        "# headers['Cookie'] = f'cf_clearance={cf_clearance}'\n",
        "\n",
        "# -------------------------\n",
        "# Download function\n",
        "# -------------------------\n",
        "\n",
        "def download_file(url):\n",
        "    filename = os.path.basename(url)\n",
        "    filepath = os.path.join(OUTPUT_FOLDER, filename)\n",
        "    print(f\"Downloading: {url} -> {filepath}\")\n",
        "    try:\n",
        "        req = urllib.request.Request(url, headers=headers)\n",
        "        with urllib.request.urlopen(req) as resp, open(filepath, 'wb') as out_file:\n",
        "            out_file.write(resp.read())\n",
        "        print(f\"‚úÖ Saved: {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error downloading {url}: {e}\")\n",
        "\n",
        "# -------------------------\n",
        "# Run downloads with optional pauses\n",
        "# -------------------------\n",
        "\n",
        "def download_all_with_pauses(urls):\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
        "        futures = []\n",
        "        for i, url in enumerate(urls):\n",
        "            futures.append(executor.submit(download_file, url))\n",
        "            if (i + 1) % PAUSE_EVERY_N == 0:\n",
        "                print(f\"\\n‚ÑπÔ∏è  Pausing for 1 second every {PAUSE_EVERY_N} downloads...\\n\")\n",
        "                time.sleep(1)  # Pause for 1 second after every PAUSE_EVERY_N downloads\n",
        "        concurrent.futures.wait(futures)\n",
        "\n",
        "download_all_with_pauses(image_urls)\n",
        "\n",
        "print(\"üéâ Done downloading all images.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r downloads.zip downloads"
      ],
      "metadata": {
        "id": "_J5ryGAx_0Ei"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}